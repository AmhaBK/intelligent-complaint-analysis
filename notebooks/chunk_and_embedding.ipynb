{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a13af37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Date received                      Product  \\\n",
      "0    2025-06-13                  Credit card   \n",
      "1    2025-06-13  Checking or savings account   \n",
      "2    2025-06-12                  Credit card   \n",
      "3    2025-06-12                  Credit card   \n",
      "4    2025-06-09                  Credit card   \n",
      "\n",
      "                                  Sub-product  \\\n",
      "0                           Store credit card   \n",
      "1                            Checking account   \n",
      "2  General-purpose credit card or charge card   \n",
      "3  General-purpose credit card or charge card   \n",
      "4  General-purpose credit card or charge card   \n",
      "\n",
      "                                             Issue  \\\n",
      "0                            Getting a credit card   \n",
      "1                              Managing an account   \n",
      "2               Other features, terms, or problems   \n",
      "3             Incorrect information on your report   \n",
      "4  Problem with a purchase shown on your statement   \n",
      "\n",
      "                                           Sub-issue  \\\n",
      "0        Card opened without my consent or knowledge   \n",
      "1                           Deposits and withdrawals   \n",
      "2                                      Other problem   \n",
      "3                      Account information incorrect   \n",
      "4  Credit card company isn't resolving a dispute ...   \n",
      "\n",
      "                        Consumer complaint narrative  \\\n",
      "0  A XXXX XXXX card was opened under my name by a...   \n",
      "1  I made the mistake of using my wellsfargo debi...   \n",
      "2  Dear CFPB, I have a secured credit card with c...   \n",
      "3  I have a Citi rewards cards. The credit balanc...   \n",
      "4  b'I am writing to dispute the following charge...   \n",
      "\n",
      "                             Company public response                Company  \\\n",
      "0  Company has responded to the consumer and the ...         CITIBANK, N.A.   \n",
      "1  Company has responded to the consumer and the ...  WELLS FARGO & COMPANY   \n",
      "2  Company has responded to the consumer and the ...         CITIBANK, N.A.   \n",
      "3  Company has responded to the consumer and the ...         CITIBANK, N.A.   \n",
      "4  Company has responded to the consumer and the ...         CITIBANK, N.A.   \n",
      "\n",
      "  State ZIP code            Tags Consumer consent provided? Submitted via  \\\n",
      "0    TX    78230   Servicemember           Consent provided           Web   \n",
      "1    ID    83815             NaN           Consent provided           Web   \n",
      "2    NY    11220             NaN           Consent provided           Web   \n",
      "3    IL    60067             NaN           Consent provided           Web   \n",
      "4    TX    78413  Older American           Consent provided           Web   \n",
      "\n",
      "  Date sent to company     Company response to consumer Timely response?  \\\n",
      "0           2025-06-13  Closed with non-monetary relief              Yes   \n",
      "1           2025-06-13          Closed with explanation              Yes   \n",
      "2           2025-06-13      Closed with monetary relief              Yes   \n",
      "3           2025-06-12          Closed with explanation              Yes   \n",
      "4           2025-06-09      Closed with monetary relief              Yes   \n",
      "\n",
      "  Consumer disputed?  Complaint ID  word_count  \\\n",
      "0                NaN      14069121          91   \n",
      "1                NaN      14061897         109   \n",
      "2                NaN      14047085         156   \n",
      "3                NaN      14040217         233   \n",
      "4                NaN      13968411         454   \n",
      "\n",
      "                                   cleaned_narrative  \n",
      "0  a xxxx xxxx card was opened under my name by a...  \n",
      "1  i made the mistake of using my wellsfargo debi...  \n",
      "2  dear cfpb i have a secured credit card with ci...  \n",
      "3  i have a citi rewards cards the credit balance...  \n",
      "4  bi am writing to dispute the following charges...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/processed/filtered_complaints.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1ed07ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word-based chunker\n",
    "def word_chunker(text, chunk_size=200, chunk_overlap=50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        chunk = words[i:i+chunk_size]\n",
    "        chunks.append(' '.join(chunk))\n",
    "        i += chunk_size - chunk_overlap\n",
    "    return chunks\n",
    "\n",
    "# Recursive character splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def recursive_chunker(text, chunk_size=600, chunk_overlap=100):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return splitter.split_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4382ded9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-based total chunks: 626628\n",
      "Recursive total chunks: 946278\n"
     ]
    }
   ],
   "source": [
    "word_chunks = []\n",
    "word_metadata = []\n",
    "\n",
    "recursive_chunks = []\n",
    "recursive_metadata = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = row['cleaned_narrative']\n",
    "    product = row['Product']\n",
    "\n",
    "    # Word-based\n",
    "    w_chunks = word_chunker(text)\n",
    "    for chunk in w_chunks:\n",
    "        word_chunks.append(chunk)\n",
    "        word_metadata.append({'product': product, 'source_row': idx, 'chunk': chunk})\n",
    "\n",
    "    # Recursive\n",
    "    r_chunks = recursive_chunker(text)\n",
    "    for chunk in r_chunks:\n",
    "        recursive_chunks.append(chunk)\n",
    "        recursive_metadata.append({'product': product, 'source_row': idx, 'chunk': chunk})\n",
    "\n",
    "print(f\"Word-based total chunks: {len(word_chunks)}\")\n",
    "print(f\"Recursive total chunks: {len(recursive_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c453d6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-based sample: 50000 chunks\n",
      "Recursive sample: 50000 chunks\n"
     ]
    }
   ],
   "source": [
    "# Choose a manageable sample size\n",
    "sample_size = 50000  # adjust if needed\n",
    "\n",
    "# Word-based sample\n",
    "word_chunks_sample = word_chunks[:sample_size]\n",
    "word_metadata_sample = word_metadata[:sample_size]\n",
    "\n",
    "# Recursive sample\n",
    "recursive_chunks_sample = recursive_chunks[:sample_size]\n",
    "recursive_metadata_sample = recursive_metadata[:sample_size]\n",
    "\n",
    "print(f\"Word-based sample: {len(word_chunks_sample)} chunks\")\n",
    "print(f\"Recursive sample: {len(recursive_chunks_sample)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad0b0d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48962de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [36:36<00:00,  5.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Word-based sample index and metadata saved.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Embed word-based sample\n",
    "word_embeddings = model.encode(\n",
    "    word_chunks_sample,\n",
    "    batch_size=128,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "word_embeddings = np.array(word_embeddings).astype('float32')\n",
    "\n",
    "# Build FAISS index\n",
    "word_index = faiss.IndexFlatL2(word_embeddings.shape[1])\n",
    "word_index.add(word_embeddings)\n",
    "\n",
    "# Save index\n",
    "faiss.write_index(word_index, '../data/processed/faiss_word_sample.index')\n",
    "\n",
    "# Save metadata\n",
    "with open('../data/processed/word_metadata_sample.pkl', 'wb') as f:\n",
    "    pickle.dump(word_metadata_sample, f)\n",
    "\n",
    "print(f\"✅ Word-based sample index and metadata saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41c9845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [27:49<00:00,  4.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Recursive sample index and metadata saved.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Embed recursive sample\n",
    "recursive_embeddings = model.encode(\n",
    "    recursive_chunks_sample,\n",
    "    batch_size=128,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "recursive_embeddings = np.array(recursive_embeddings).astype('float32')\n",
    "\n",
    "# Build FAISS index\n",
    "recursive_index = faiss.IndexFlatL2(recursive_embeddings.shape[1])\n",
    "recursive_index.add(recursive_embeddings)\n",
    "\n",
    "# Save index\n",
    "faiss.write_index(recursive_index, '../data/processed/faiss_recursive_sample.index')\n",
    "\n",
    "# Save metadata\n",
    "with open('../data/processed/recursive_metadata_sample.pkl', 'wb') as f:\n",
    "    pickle.dump(recursive_metadata_sample, f)\n",
    "\n",
    "print(f\"✅ Recursive sample index and metadata saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed963e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Word-based top 5:\n",
      "- card on xxxxyear and told the person this charge was excessive and they refused to offer credit to my account i was refused credit or any consideration by xxxx different peopleas a xxxx xxxx xxxx xxxx ...\n",
      "- by the website itself i am still being charged interest on a card i simply can not pay the balance of again i repeat this is the case of many people these are unjust and illegal practices by comenity  ...\n",
      "- actions when it comes to using a credit card ...\n",
      "- i have a couple of store credit cards and noticed they are now charging a fee for paper statements i feel this is something the cfpb should address as it is taking advantage of the consumer digital st ...\n",
      "- a productive call and hung up on me it is predatory to add on fees before a payment is made and to not have that included in the payment when opting to pay off the entire card and it is predatory to o ...\n",
      "\n",
      "🔍 Recursive top 5:\n",
      "- it makes it confusing so that they can assess these insane rates higher than any credit card i have ever seen \n",
      "their language is deceitful and done on purpose and puts people in more of a financial st ...\n",
      "- credit card companies like amex already profit off standard interest and fees but punishing customers who pay on time by hiding behind fine print is exactly what people get trapped in credit debt that ...\n",
      "- while i appreciate the reversals the pattern of fee generation and high minimum payments continues making it difficult to manage payments and creating undue stress the repetitive nature of these incid ...\n",
      "- them on time without issue but because i choose to use cards with a lower interest over there xxxx percent and not own a home they want to penalize me and damage my credit ...\n",
      "- the case unless the perpetrator left a detailed paper receipt of their actions my finances have been assaulted and charged an additional 70000 but they are blaming me for not being able to show exactl ...\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "# Example test query\n",
    "query = \"Why are people unhappy with credit card charges?\"\n",
    "query_embedding = model.encode([query]).astype('float32')\n",
    "\n",
    "word_index = faiss.read_index('../data/processed/faiss_word_sample.index')\n",
    "\n",
    "# Word-based search\n",
    "D_word, I_word = word_index.search(query_embedding, k=5)\n",
    "print(\"\\n🔍 Word-based top 5:\")\n",
    "for i in I_word[0]:\n",
    "    print(\"-\", word_chunks_sample[i][:200], \"...\")\n",
    "\n",
    "recursive_index = faiss.read_index('../data/processed/faiss_recursive_sample.index')\n",
    "\n",
    "# Recursive search\n",
    "D_rec, I_rec = recursive_index.search(query_embedding, k=5)\n",
    "print(\"\\n🔍 Recursive top 5:\")\n",
    "for i in I_rec[0]:\n",
    "    print(\"-\", recursive_chunks_sample[i][:200], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7619d80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 50000 chunks\n",
      "Original metadata entries: 50000\n",
      "✅ New sample metadata example: {'product': 'Credit card', 'source_row': 0, 'chunk': 'a xxxx xxxx card was opened under my name by a fraudster i received a notice from xxxx  that an account was just opened under my name i reached out to xxxx xxxx to state that this activity was unauthorized and not me xxxx xxxx confirmed this was fraudulent and immediately closed the card however they have failed to remove this from the three credit agencies and this fraud is now impacting my credit score based on a hard credit pull done by xxxx xxxx that was done by a fraudster'}\n",
      "✅ Done! Your sample metadata now includes the chunk text.\n"
     ]
    }
   ],
   "source": [
    "# Rebuild the sample recursive metadata with the chunk text included\n",
    "\n",
    "import pickle\n",
    "\n",
    "print(f\"Sample size: {len(recursive_chunks_sample)} chunks\")\n",
    "print(f\"Original metadata entries: {len(recursive_metadata_sample)}\")\n",
    "\n",
    "# ✅ Rebuild metadata for the sample to include `chunk` text\n",
    "recursive_sample_metadata = []\n",
    "for old_meta, chunk in zip(recursive_metadata_sample, recursive_chunks_sample):\n",
    "    new_meta = dict(old_meta)\n",
    "    new_meta[\"chunk\"] = chunk\n",
    "    recursive_sample_metadata.append(new_meta)\n",
    "\n",
    "print(\"✅ New sample metadata example:\", recursive_sample_metadata[0])\n",
    "\n",
    "# ✅ Save the fixed sample metadata\n",
    "with open(\"../vector_store/recursive_sample_metadata.pkl\", \"wb\") as f:\n",
    "    pickle.dump(recursive_sample_metadata, f)\n",
    "\n",
    "print(\"✅ Done! Your sample metadata now includes the chunk text.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
