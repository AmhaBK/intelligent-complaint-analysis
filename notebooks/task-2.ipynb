{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a13af37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Date received                      Product  \\\n",
      "0    2025-06-13                  Credit card   \n",
      "1    2025-06-13  Checking or savings account   \n",
      "2    2025-06-12                  Credit card   \n",
      "3    2025-06-12                  Credit card   \n",
      "4    2025-06-09                  Credit card   \n",
      "\n",
      "                                  Sub-product  \\\n",
      "0                           Store credit card   \n",
      "1                            Checking account   \n",
      "2  General-purpose credit card or charge card   \n",
      "3  General-purpose credit card or charge card   \n",
      "4  General-purpose credit card or charge card   \n",
      "\n",
      "                                             Issue  \\\n",
      "0                            Getting a credit card   \n",
      "1                              Managing an account   \n",
      "2               Other features, terms, or problems   \n",
      "3             Incorrect information on your report   \n",
      "4  Problem with a purchase shown on your statement   \n",
      "\n",
      "                                           Sub-issue  \\\n",
      "0        Card opened without my consent or knowledge   \n",
      "1                           Deposits and withdrawals   \n",
      "2                                      Other problem   \n",
      "3                      Account information incorrect   \n",
      "4  Credit card company isn't resolving a dispute ...   \n",
      "\n",
      "                        Consumer complaint narrative  \\\n",
      "0  A XXXX XXXX card was opened under my name by a...   \n",
      "1  I made the mistake of using my wellsfargo debi...   \n",
      "2  Dear CFPB, I have a secured credit card with c...   \n",
      "3  I have a Citi rewards cards. The credit balanc...   \n",
      "4  b'I am writing to dispute the following charge...   \n",
      "\n",
      "                             Company public response                Company  \\\n",
      "0  Company has responded to the consumer and the ...         CITIBANK, N.A.   \n",
      "1  Company has responded to the consumer and the ...  WELLS FARGO & COMPANY   \n",
      "2  Company has responded to the consumer and the ...         CITIBANK, N.A.   \n",
      "3  Company has responded to the consumer and the ...         CITIBANK, N.A.   \n",
      "4  Company has responded to the consumer and the ...         CITIBANK, N.A.   \n",
      "\n",
      "  State ZIP code            Tags Consumer consent provided? Submitted via  \\\n",
      "0    TX    78230   Servicemember           Consent provided           Web   \n",
      "1    ID    83815             NaN           Consent provided           Web   \n",
      "2    NY    11220             NaN           Consent provided           Web   \n",
      "3    IL    60067             NaN           Consent provided           Web   \n",
      "4    TX    78413  Older American           Consent provided           Web   \n",
      "\n",
      "  Date sent to company     Company response to consumer Timely response?  \\\n",
      "0           2025-06-13  Closed with non-monetary relief              Yes   \n",
      "1           2025-06-13          Closed with explanation              Yes   \n",
      "2           2025-06-13      Closed with monetary relief              Yes   \n",
      "3           2025-06-12          Closed with explanation              Yes   \n",
      "4           2025-06-09      Closed with monetary relief              Yes   \n",
      "\n",
      "  Consumer disputed?  Complaint ID  word_count  \\\n",
      "0                NaN      14069121          91   \n",
      "1                NaN      14061897         109   \n",
      "2                NaN      14047085         156   \n",
      "3                NaN      14040217         233   \n",
      "4                NaN      13968411         454   \n",
      "\n",
      "                                   cleaned_narrative  \n",
      "0  a xxxx xxxx card was opened under my name by a...  \n",
      "1  i made the mistake of using my wellsfargo debi...  \n",
      "2  dear cfpb i have a secured credit card with ci...  \n",
      "3  i have a citi rewards cards the credit balance...  \n",
      "4  bi am writing to dispute the following charges...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/processed/filtered_complaints.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1ed07ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word-based chunker\n",
    "def word_chunker(text, chunk_size=200, chunk_overlap=50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        chunk = words[i:i+chunk_size]\n",
    "        chunks.append(' '.join(chunk))\n",
    "        i += chunk_size - chunk_overlap\n",
    "    return chunks\n",
    "\n",
    "# Recursive character splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def recursive_chunker(text, chunk_size=600, chunk_overlap=100):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return splitter.split_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4382ded9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-based total chunks: 626628\n",
      "Recursive total chunks: 946278\n"
     ]
    }
   ],
   "source": [
    "word_chunks = []\n",
    "word_metadata = []\n",
    "\n",
    "recursive_chunks = []\n",
    "recursive_metadata = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = row['cleaned_narrative']\n",
    "    product = row['Product']\n",
    "\n",
    "    # Word-based\n",
    "    w_chunks = word_chunker(text)\n",
    "    for chunk in w_chunks:\n",
    "        word_chunks.append(chunk)\n",
    "        word_metadata.append({'product': product, 'source_row': idx})\n",
    "\n",
    "    # Recursive\n",
    "    r_chunks = recursive_chunker(text)\n",
    "    for chunk in r_chunks:\n",
    "        recursive_chunks.append(chunk)\n",
    "        recursive_metadata.append({'product': product, 'source_row': idx})\n",
    "\n",
    "print(f\"Word-based total chunks: {len(word_chunks)}\")\n",
    "print(f\"Recursive total chunks: {len(recursive_chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c453d6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-based sample: 50000 chunks\n",
      "Recursive sample: 50000 chunks\n"
     ]
    }
   ],
   "source": [
    "# Choose a manageable sample size\n",
    "sample_size = 50000  # adjust if needed\n",
    "\n",
    "# Word-based sample\n",
    "word_chunks_sample = word_chunks[:sample_size]\n",
    "word_metadata_sample = word_metadata[:sample_size]\n",
    "\n",
    "# Recursive sample\n",
    "recursive_chunks_sample = recursive_chunks[:sample_size]\n",
    "recursive_metadata_sample = recursive_metadata[:sample_size]\n",
    "\n",
    "print(f\"Word-based sample: {len(word_chunks_sample)} chunks\")\n",
    "print(f\"Recursive sample: {len(recursive_chunks_sample)} chunks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad0b0d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mike\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48962de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [36:36<00:00,  5.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Word-based sample index and metadata saved.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Embed word-based sample\n",
    "word_embeddings = model.encode(\n",
    "    word_chunks_sample,\n",
    "    batch_size=128,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "word_embeddings = np.array(word_embeddings).astype('float32')\n",
    "\n",
    "# Build FAISS index\n",
    "word_index = faiss.IndexFlatL2(word_embeddings.shape[1])\n",
    "word_index.add(word_embeddings)\n",
    "\n",
    "# Save index\n",
    "faiss.write_index(word_index, '../data/processed/faiss_word_sample.index')\n",
    "\n",
    "# Save metadata\n",
    "with open('../data/processed/word_metadata_sample.pkl', 'wb') as f:\n",
    "    pickle.dump(word_metadata_sample, f)\n",
    "\n",
    "print(f\"✅ Word-based sample index and metadata saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41c9845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [27:49<00:00,  4.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Recursive sample index and metadata saved.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Embed recursive sample\n",
    "recursive_embeddings = model.encode(\n",
    "    recursive_chunks_sample,\n",
    "    batch_size=128,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "recursive_embeddings = np.array(recursive_embeddings).astype('float32')\n",
    "\n",
    "# Build FAISS index\n",
    "recursive_index = faiss.IndexFlatL2(recursive_embeddings.shape[1])\n",
    "recursive_index.add(recursive_embeddings)\n",
    "\n",
    "# Save index\n",
    "faiss.write_index(recursive_index, '../data/processed/faiss_recursive_sample.index')\n",
    "\n",
    "# Save metadata\n",
    "with open('../data/processed/recursive_metadata_sample.pkl', 'wb') as f:\n",
    "    pickle.dump(recursive_metadata_sample, f)\n",
    "\n",
    "print(f\"✅ Recursive sample index and metadata saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ed963e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Word-based top 5:\n",
      "- card on xxxxyear and told the person this charge was excessive and they refused to offer credit to my account i was refused credit or any consideration by xxxx different peopleas a xxxx xxxx xxxx xxxx ...\n",
      "- by the website itself i am still being charged interest on a card i simply can not pay the balance of again i repeat this is the case of many people these are unjust and illegal practices by comenity  ...\n",
      "- actions when it comes to using a credit card ...\n",
      "- i have a couple of store credit cards and noticed they are now charging a fee for paper statements i feel this is something the cfpb should address as it is taking advantage of the consumer digital st ...\n",
      "- a productive call and hung up on me it is predatory to add on fees before a payment is made and to not have that included in the payment when opting to pay off the entire card and it is predatory to o ...\n",
      "\n",
      "🔍 Recursive top 5:\n",
      "- it makes it confusing so that they can assess these insane rates higher than any credit card i have ever seen \n",
      "their language is deceitful and done on purpose and puts people in more of a financial st ...\n",
      "- credit card companies like amex already profit off standard interest and fees but punishing customers who pay on time by hiding behind fine print is exactly what people get trapped in credit debt that ...\n",
      "- while i appreciate the reversals the pattern of fee generation and high minimum payments continues making it difficult to manage payments and creating undue stress the repetitive nature of these incid ...\n",
      "- them on time without issue but because i choose to use cards with a lower interest over there xxxx percent and not own a home they want to penalize me and damage my credit ...\n",
      "- the case unless the perpetrator left a detailed paper receipt of their actions my finances have been assaulted and charged an additional 70000 but they are blaming me for not being able to show exactl ...\n"
     ]
    }
   ],
   "source": [
    "# Example test query\n",
    "query = \"Why are people unhappy with credit card charges?\"\n",
    "query_embedding = model.encode([query]).astype('float32')\n",
    "\n",
    "# Word-based search\n",
    "D_word, I_word = word_index.search(query_embedding, k=5)\n",
    "print(\"\\n🔍 Word-based top 5:\")\n",
    "for i in I_word[0]:\n",
    "    print(\"-\", word_chunks_sample[i][:200], \"...\")\n",
    "\n",
    "# Recursive search\n",
    "D_rec, I_rec = recursive_index.search(query_embedding, k=5)\n",
    "print(\"\\n🔍 Recursive top 5:\")\n",
    "for i in I_rec[0]:\n",
    "    print(\"-\", recursive_chunks_sample[i][:200], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d4e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# ✅ 1️⃣ Imports & setup\n",
    "# --------------------------------------------\n",
    "\n",
    "import faiss\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load embedder\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
    "\n",
    "# Load your FAISS index & metadata — pick which one\n",
    "INDEX_PATH = '../data/preprocessing/faiss_recursive_sample.index'\n",
    "META_PATH = '../data/preprocessing/recursive_metadata_sample.pkl'\n",
    "CHUNK_SOURCE = 'recursive'  # or 'word'\n",
    "\n",
    "# Load index\n",
    "index = faiss.read_index(INDEX_PATH)\n",
    "\n",
    "# Load metadata\n",
    "with open(META_PATH, 'rb') as f:\n",
    "    metadata = pickle.load(f)\n",
    "\n",
    "# Load the same chunks again for output — optional if needed\n",
    "# If you have them saved in a file, load here\n",
    "# For now, store them in your session:\n",
    "from pathlib import Path\n",
    "\n",
    "# If needed: you can store chunks in metadata too\n",
    "# For this template we’ll just read from metadata\n",
    "\n",
    "# Load small LLM\n",
    "llm = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    device=0 if device == 'cuda' else -1,\n",
    "    max_new_tokens=300\n",
    ")\n",
    "\n",
    "print(\"✅ LLM pipeline ready\")\n",
    "\n",
    "# --------------------------------------------\n",
    "# ✅ 2️⃣ Retrieval function\n",
    "# --------------------------------------------\n",
    "\n",
    "def retrieve_top_k(query, k=5):\n",
    "    query_emb = embedder.encode([query]).astype('float32')\n",
    "    D, I = index.search(query_emb, k)\n",
    "    results = []\n",
    "    for idx in I[0]:\n",
    "        # metadata should contain: chunk, product, source row, etc.\n",
    "        result = {\n",
    "            \"chunk\": metadata[idx]['chunk'],  # Store chunk in metadata!\n",
    "            \"metadata\": metadata[idx]\n",
    "        }\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "# --------------------------------------------\n",
    "# ✅ 3️⃣ Prompt generator\n",
    "# --------------------------------------------\n",
    "\n",
    "def generate_answer(query, top_chunks):\n",
    "    context = \"\\n\\n\".join([c['chunk'] for c in top_chunks])\n",
    "    prompt = f\"\"\"\n",
    "You are an internal AI assistant for CrediTrust.\n",
    "Use ONLY the context below to answer the question.\n",
    "If the context does not answer it, say \"I don't have enough information.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    output = llm(prompt)\n",
    "    return output[0]['generated_text']\n",
    "\n",
    "# --------------------------------------------\n",
    "# ✅ 4️⃣ End-to-end example\n",
    "# --------------------------------------------\n",
    "\n",
    "question = \"Why are people unhappy with credit card charges?\"\n",
    "retrieved = retrieve_top_k(question, k=5)\n",
    "\n",
    "print(\"\\n🔍 Top retrieved chunks:\")\n",
    "for r in retrieved:\n",
    "    print(\"-\", r['chunk'][:200], \"...\")\n",
    "\n",
    "answer = generate_answer(question, retrieved)\n",
    "\n",
    "print(\"\\n✅ Final generated answer:\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
